#!/usr/bin/env python

r"""
This script takes runs through a list of Logs in a given time interval
and calculates the customer impact. 

It lists all the SUCCESSFUL deployments as:
DEPLOYMENT&PASS&<ACCOUNT_ID>&<TIME>&<deploymentId>

It lists all the FAILED deployments as:
DEPLOYMENT&FAIL&<ACCOUNT_ID>&<TIME>&<deploymentId>

It lists all the FAILED_WITH_INTERNAL_ERROR deployments as:
DEPLOYMENT&FAIL_INTERNAL&<ACCOUNT_ID>&<TIME>&<deploymentId>

The & delimiter makes the output script parsable easily
"""
import datetime
import os
import glob
import time
import re
import gzip

class CustomerImpact:
    #Return date from string
	@staticmethod
	def getDate(datestr):
		if datestr == None:
			return datetime.datetime.now()
		t = None
		if len(datestr.split("-")) == 1:
			t = time.gmtime(float(datestr))
		else:
			try:
				t = time.strptime(datestr, "%Y-%m-%d-%H-%M")
			except:
				print("Could not convert date: " + datestr + ". Needs to be %Y-%m-%d-%H-%M")
				sys.exit(1)
		tstamp = time.mktime(t)
		return datetime.datetime.fromtimestamp(tstamp)
	
	# Compute files to check
	@staticmethod
	def fileLogic(root, start = None, end = None):
		filelist = glob.glob(root + "/service_log.*")
		filelist.extend(glob.glob(root + "/service_log.*.gz"))
		filelist.extend(glob.glob(root + "/transmitted/service_log.*.gz"))
		retval = []

		if start == None:
			givenstart = datetime.datetime.now() - datetime.timedelta(hours = 48)
		else:
			givenstart = CustomerImpact.getDate(start) - datetime.timedelta(hours = 1)
		if end == None:
			givenend = datetime.datetime.now()
		else:
			givenend = CustomerImpact.getDate(end)
		
		for f in filelist:
			fdate = CustomerImpact.getDate(f.split(".")[1] + "-00")
			if not (fdate < givenstart or fdate > givenend):
				retval.append(f)
		return retval

	# Main Grep function
	@staticmethod
	def grep(filename, start = None, end = None):
		fail = dict()
		success = dict()
		failInternal = dict()

		if filename.endswith(".gz"):
			fp = gzip.open(filename, "r")
		else:
			fp = open(filename, "r")
		logs = fp.read().split("EOE")
		print("Inspecting " + filename)	
		for query in logs:
			try:
				logic = True
				status = re.search("DeploymentStatus=(.*)", query, re.MULTILINE)
				operation = re.search("Operation=ExecuteDeployment", query, re.MULTILINE)
				deploymentId = re.search("deploymentId=(.*)", query, re.MULTILINE | re.I)
				acct = re.search("AwsAccountId=(.*)", query, re.MULTILINE | re.I)
				qetime = None
				if not (operation):
					logic = False
				# Look at start and end time
				if logic and (start != None or end != None):
					operationEndTime = re.search("EndTime=(.*)", query, re.MULTILINE)
					if operationEndTime:
						qetime = datetime.datetime.fromtimestamp(time.mktime(time.strptime(operationEndTime.group(1), "%a, %d %b %Y  %H:%M:%S %Z")))
						if qetime < CustomerImpact.getDate(end) and qetime > CustomerImpact.getDate(start):
							logic = True
						else:
							logic = False
				if logic:
					# Check for failed deployments
					if status.group(1) == "Failed":
						internal = re.search("Deployment-Metric-Fault=1", query, re.MULTILINE)
						if internal: # Failed with internal errors
							print("DEPLOYMENT&FAIL_INTERNAL&" + acct.group(1)  + "&" + str(qetime) + "&" + deploymentId.group(1))
						else: # Failed without internal errors
							print("DEPLOYMENT&FAIL&" + acct.group(1) + "&" + str(qetime) + "&" + deploymentId.group(1))
					# Check for succeeded deployments
				        else:
						print("DEPLOYMENT&PASS&" + acct.group(1) + "&" + str(qetime) + "&" + deploymentId.group(1))
			except:
				pass
		
def main():
	start = "START_P"
	end = "END_P"
	if start == "None":
		start = None
	if end == "None":
		end = None
	root = "/apollo/env/RazorbillDeploymentService/var/output/logs"
	filelist = CustomerImpact.fileLogic(root, start, end)
	
	for f in filelist:
		CustomerImpact.grep(f, start,end)
	
if __name__ == "__main__":
	main()
